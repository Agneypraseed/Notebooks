{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["'2.4.1+cpu'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","torch.__version__"]},{"cell_type":"markdown","metadata":{},"source":["`torch.Tensor` is PyTorch's main data structure for numerical computations.\n","\n","It represents a multi-dimensional array (similar to NumPy arrays), and is the basic building block for all operations the basic building block for all operations in PyTorch.\n","\n","Tensors store and operate on numerical data.\n","\n","It can seamlessly run on both CPUs and GPUs"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(3)\n","0\n"]},{"data":{"text/plain":["3"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Scalar\n","scalar = torch.tensor(3)\n","print(scalar)\n","\n","print(scalar.ndim)\n","\n","# Get the Python number within a tensor (only works with one-element tensors)\n","scalar.item()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([7, 7])\n","1\n","torch.Size([2])\n"]}],"source":["# Vector\n","vector = torch.tensor([7, 7])\n","print(vector)\n","print(vector.ndim)\n","print(vector.shape)\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 7,  8],\n","        [ 9, 10]])\n","2\n","torch.Size([2, 2])\n"]}],"source":["#matrix\n","\n","matrix = torch.tensor([[7, 8], \n","                       [9, 10]])\n","\n","print(matrix)\n","print(matrix.ndim)\n","print(matrix.shape)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[1, 2, 3],\n","         [3, 6, 9],\n","         [2, 4, 5]]])\n","3\n","torch.Size([1, 3, 3])\n"]}],"source":["# Tensor\n","TENSOR = torch.tensor([[[1, 2, 3],\n","                        [3, 6, 9],\n","                        [2, 4, 5]]])\n","\n","print(TENSOR)\n","print(TENSOR.ndim)\n","print(TENSOR.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1, 2, 3],\n","        [3, 6, 9],\n","        [2, 4, 5]])\n"]}],"source":["print(TENSOR[0])"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([2, 3, 3])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# In the tensor with 2 blocks (2, 3, 3), you have 2 layers (or blocks), and each layer has 3 rows and 3 columns.\n","TENSOR_2_BLOCKS = torch.tensor([[[1, 2, 3],\n","                                 [3, 6, 9],\n","                                 [2, 4, 5]],\n","                               \n","                                [[7, 8, 9],\n","                                 [4, 2, 1],\n","                                 [0, 3, 6]]])\n","\n","TENSOR_2_BLOCKS.shape"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["(tensor([[0.7795, 0.4307, 0.8854, 0.1587],\n","         [0.4132, 0.1441, 0.5037, 0.0884],\n","         [0.5474, 0.7252, 0.9960, 0.9413]]),\n"," torch.float32)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Create a random tensor of size (3, 4)\n","random_tensor = torch.rand(size=(3, 4))\n","random_tensor, random_tensor.dtype"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["(tensor([[[0.8761, 0.7252, 0.2542, 0.9455],\n","          [0.3950, 0.0696, 0.5708, 0.7618],\n","          [0.6129, 0.2280, 0.5504, 0.9211]],\n"," \n","         [[0.3241, 0.3455, 0.8487, 0.5120],\n","          [0.1980, 0.9256, 0.1883, 0.3846],\n","          [0.0709, 0.5534, 0.1068, 0.4564]],\n"," \n","         [[0.3827, 0.9254, 0.4141, 0.0496],\n","          [0.7526, 0.7036, 0.7747, 0.6082],\n","          [0.3656, 0.4213, 0.0510, 0.4785]]]),\n"," torch.float32)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["random_tensor = torch.rand(size=(3,3,4))\n","random_tensor, random_tensor.dtype"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["(tensor([[0., 0., 0., 0.],\n","         [0., 0., 0., 0.],\n","         [0., 0., 0., 0.]]),\n"," torch.float32)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# Create a tensor of all zeros\n","zeros = torch.zeros(size=(3, 4))\n","zeros, zeros.dtype"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'torch' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a range of values 0 to 10\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m zero_to_ten \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39marange(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m zero_to_ten\n","\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"]}],"source":["# Create a range of values 0 to 10\n","zero_to_ten = torch.arange(start=0, end=10, step=1)\n","zero_to_ten"]},{"cell_type":"markdown","metadata":{},"source":["Automatic Differentiation: PyTorch tensors can track gradients, which is essential for training neural networks. By setting requires_grad=True, PyTorch will automatically calculate derivatives (gradients) for tensor operations, which is used for backpropagation in training."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[ 2., -2.],\n","        [ 2.,  2.]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True)\n","out = x.pow(2).sum()\n","\n","out.backward()\n","\n","x.grad"]},{"cell_type":"markdown","metadata":{},"source":["    If you're using CUDA (like with an NVIDIA GPU), you can move a tensor to the GPU to perform computations much faster."]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["tensor_cpu = torch.Tensor([1.0, 2.0, 3.0])  # on CPU\n","# tensor_gpu = tensor_cpu.to('cuda')           # move to GPU (if available)"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-15T14:58:11.043965Z","iopub.status.busy":"2023-12-15T14:58:11.043370Z","iopub.status.idle":"2023-12-15T14:58:11.053874Z","shell.execute_reply":"2023-12-15T14:58:11.052595Z","shell.execute_reply.started":"2023-12-15T14:58:11.043918Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0, 1, 2])\n","torch.Size([3])\n","1\n"]}],"source":["import torch\n","\n","one_d_t =  torch.LongTensor([0,1,2])\n","print(one_d_t)\n","print(one_d_t.size())\n","print(one_d_t.dim())"]},{"cell_type":"markdown","metadata":{},"source":["The unsqueeze operation in PyTorch is used to add a dimension to a tensor at a specified location\n","\n","if you have a batch of images represented as a tensor of shape (batch_size, height, width, channels), you might use unsqueeze to add a batch dimension at the beginning, resulting in a tensor of shape (batch_size, 1, height, width, channels)."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T14:58:26.134482Z","iopub.status.busy":"2023-12-15T14:58:26.133787Z","iopub.status.idle":"2023-12-15T14:58:26.143707Z","shell.execute_reply":"2023-12-15T14:58:26.142817Z","shell.execute_reply.started":"2023-12-15T14:58:26.134436Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 3])\n","2\n"]},{"data":{"text/plain":["tensor([[0, 1, 2]])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["two_d_t = one_d_t.unsqueeze(0)\n","print(two_d_t.size())\n","print(two_d_t.dim())\n","two_d_t"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T14:59:27.681148Z","iopub.status.busy":"2023-12-15T14:59:27.680599Z","iopub.status.idle":"2023-12-15T14:59:27.690812Z","shell.execute_reply":"2023-12-15T14:59:27.689432Z","shell.execute_reply.started":"2023-12-15T14:59:27.681107Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Original Tensor: tensor([1, 2, 3]) torch.Size([3]) 1\n","Unsqueezed Tensor: tensor([[1],\n","        [2],\n","        [3]]) torch.Size([3, 1]) 2\n"]}],"source":["original_tensor = torch.tensor([1, 2, 3])\n","\n","# Unsqueeze operation to add a dimension at the specified location (index 1 in this case)\n","unsqueezed_tensor = original_tensor.unsqueeze(1)\n","\n","# Print the original and unsqueezed tensors\n","print(\"Original Tensor:\", original_tensor, original_tensor.shape, original_tensor.dim())\n","print(\"Unsqueezed Tensor:\", unsqueezed_tensor, unsqueezed_tensor.shape, unsqueezed_tensor.dim() )"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-12-15T15:04:17.594708Z","iopub.status.busy":"2023-12-15T15:04:17.593362Z","iopub.status.idle":"2023-12-15T15:04:17.618798Z","shell.execute_reply":"2023-12-15T15:04:17.617580Z","shell.execute_reply.started":"2023-12-15T15:04:17.594645Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Original Matrix:\n","tensor([[1, 2, 3],\n","        [4, 5, 6],\n","        [7, 8, 9]])\n","\n","Transposed Matrix (torch.transpose):\n","tensor([[1, 4, 7],\n","        [2, 5, 8],\n","        [3, 6, 9]])\n","\n","Transposed Matrix (.t() method):\n","tensor([[1, 4, 7],\n","        [2, 5, 8],\n","        [3, 6, 9]])\n"]}],"source":["import torch\n","\n","# Original matrix\n","original_matrix = torch.tensor([[1, 2, 3],\n","                                [4, 5, 6],\n","                                [7, 8, 9]])\n","\n","# Transpose using torch.transpose\n","transposed_matrix = torch.transpose(original_matrix, 0, 1)\n","\n","# Transpose using .t() method\n","t_method_transposed_matrix = original_matrix.t()\n","\n","# Print the original and transposed matrices\n","print(\"Original Matrix:\")\n","print(original_matrix)\n","print(\"\\nTransposed Matrix (torch.transpose):\")\n","print(transposed_matrix)\n","print(\"\\nTransposed Matrix (.t() method):\")\n","print(t_method_transposed_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
