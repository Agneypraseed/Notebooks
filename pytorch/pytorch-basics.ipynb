{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"text/plain":["'2.4.1+cpu'"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","torch.__version__"]},{"cell_type":"markdown","metadata":{},"source":["`torch.Tensor` is PyTorch's main data structure for numerical computations.\n","\n","It represents a multi-dimensional array (similar to NumPy arrays), and is the basic building block for all operations the basic building block for all operations in PyTorch.\n","\n","Tensors store and operate on numerical data.\n","\n","It can seamlessly run on both CPUs and GPUs"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(3)\n","0\n"]},{"data":{"text/plain":["3"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Scalar\n","scalar = torch.tensor(3)\n","print(scalar)\n","\n","print(scalar.ndim)\n","\n","# Get the Python number within a tensor (only works with one-element tensors)\n","scalar.item()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([7, 7])\n","1\n","torch.Size([2])\n"]}],"source":["# Vector\n","vector = torch.tensor([7, 7])\n","print(vector)\n","print(vector.ndim)\n","print(vector.shape)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 7,  8],\n","        [ 9, 10]])\n","2\n","torch.Size([2, 2])\n"]}],"source":["#matrix\n","\n","matrix = torch.tensor([[7, 8], \n","                       [9, 10]])\n","\n","print(matrix)\n","print(matrix.ndim)\n","print(matrix.shape)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[1, 2, 3],\n","         [3, 6, 9],\n","         [2, 4, 5]]])\n","3\n","torch.Size([1, 3, 3])\n"]}],"source":["# Tensor\n","TENSOR = torch.tensor([[[1, 2, 3],\n","                        [3, 6, 9],\n","                        [2, 4, 5]]])\n","\n","print(TENSOR)\n","print(TENSOR.ndim)\n","print(TENSOR.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1, 2, 3],\n","        [3, 6, 9],\n","        [2, 4, 5]])\n"]}],"source":["print(TENSOR[0])"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([2, 3, 3])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# In the tensor with 2 blocks (2, 3, 3), you have 2 layers (or blocks), and each layer has 3 rows and 3 columns.\n","TENSOR_2_BLOCKS = torch.tensor([[[1, 2, 3],\n","                                 [3, 6, 9],\n","                                 [2, 4, 5]],\n","                               \n","                                [[7, 8, 9],\n","                                 [4, 2, 1],\n","                                 [0, 3, 6]]])\n","\n","TENSOR_2_BLOCKS.shape"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["(tensor([[0.7795, 0.4307, 0.8854, 0.1587],\n","         [0.4132, 0.1441, 0.5037, 0.0884],\n","         [0.5474, 0.7252, 0.9960, 0.9413]]),\n"," torch.float32)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Create a random tensor of size (3, 4)\n","random_tensor = torch.rand(size=(3, 4))\n","random_tensor, random_tensor.dtype"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["(tensor([[[0.8761, 0.7252, 0.2542, 0.9455],\n","          [0.3950, 0.0696, 0.5708, 0.7618],\n","          [0.6129, 0.2280, 0.5504, 0.9211]],\n"," \n","         [[0.3241, 0.3455, 0.8487, 0.5120],\n","          [0.1980, 0.9256, 0.1883, 0.3846],\n","          [0.0709, 0.5534, 0.1068, 0.4564]],\n"," \n","         [[0.3827, 0.9254, 0.4141, 0.0496],\n","          [0.7526, 0.7036, 0.7747, 0.6082],\n","          [0.3656, 0.4213, 0.0510, 0.4785]]]),\n"," torch.float32)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["random_tensor = torch.rand(size=(3,3,4))\n","random_tensor, random_tensor.dtype"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["(tensor([[0., 0., 0., 0.],\n","         [0., 0., 0., 0.],\n","         [0., 0., 0., 0.]]),\n"," torch.float32)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# Create a tensor of all zeros\n","zeros = torch.zeros(size=(3, 4))\n","zeros, zeros.dtype"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([0, 3, 6, 9])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Create a range of values 0 to 10\n","zero_to_ten = torch.arange(start=0, end=10, step=3)\n","zero_to_ten"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["(torch.Size([3]), torch.float32, device(type='cpu'))"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["float_default_tensor = torch.tensor([3.0, 6.0, 9.0],\n","                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n","                               device=None, # defaults to None, which uses the default tensor type\n","                               requires_grad=False) # if True, operations performed on the tensor are recorded \n","\n","float_default_tensor.shape, float_default_tensor.dtype, float_default_tensor.device"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["(torch.float16, tensor([3., 6., 9.], dtype=torch.float16))"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n","                               dtype=torch.float16) # torch.half would also work\n","\n","float_16_tensor.dtype"]},{"cell_type":"markdown","metadata":{},"source":["Automatic Differentiation: PyTorch tensors can track gradients, which is essential for training neural networks. By setting requires_grad=True, PyTorch will automatically calculate derivatives (gradients) for tensor operations, which is used for backpropagation in training."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[ 2., -2.],\n","        [ 2.,  2.]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True)\n","out = x.pow(2).sum()\n","\n","out.backward()\n","\n","x.grad"]},{"cell_type":"markdown","metadata":{},"source":["    If you're using CUDA (like with an NVIDIA GPU), you can move a tensor to the GPU to perform computations much faster."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["False"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# Check for GPU\n","import torch\n","torch.cuda.is_available()"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Count number of devices\n","torch.cuda.device_count()"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["tensor_cpu = torch.Tensor([1.0, 2.0, 3.0])  # on CPU\n","# tensor_gpu = tensor_cpu.to('cuda')           # move to GPU (if available)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["'cpu'"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Set device type\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1, 2, 3]) cpu\n"]},{"data":{"text/plain":["tensor([1, 2, 3])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Create tensor (default on CPU)\n","tensor = torch.tensor([1, 2, 3])\n","\n","# Tensor not on GPU\n","print(tensor, tensor.device)\n","\n","# Move tensor to GPU (if available)\n","tensor_on_gpu = tensor.to(device) # Putting a tensor on GPU using to(device) returns a copy of that tensor, e.g. the same tensor will be on CPU and GPU\n","tensor_on_gpu"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["array([1, 2, 3])"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# Moving tensors back to the CPU\n","\n","# NumPy does not leverage the GPU\n","\n","# If tensor is on GPU, can't transform it to NumPy (this will error)\n","# tensor_on_gpu.numpy()\n","\n","tensor_back_on_cpu = tensor_on_gpu.cpu().numpy() # This returns a copy of the GPU tensor in CPU memory so the original tensor is still on GPU.\n","tensor_back_on_cpu"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Equals: tensor([1, 4, 9])\n","tensor(14)\n","tensor(14)\n"]}],"source":["# Multiplication \n","\n","# Element wise multiplication\n","\n","tensor = torch.tensor([1, 2, 3])\n","\n","print(\"Equals:\", tensor * tensor)\n","\n","# Matrix Multiplication / Dot Product\n","\n","print(torch.matmul(tensor, tensor))\n","print(tensor @ tensor)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: total: 0 ns\n","Wall time: 1.3 ms\n"]},{"data":{"text/plain":["tensor(14)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","value = 0\n","for i in range(len(tensor)):\n","  value += tensor[i] * tensor[i]\n","value"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: total: 0 ns\n","Wall time: 0 ns\n"]},{"data":{"text/plain":["tensor(14)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","torch.matmul(tensor, tensor)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 7.,  8.,  9.],\n","        [10., 11., 12.]]) torch.Size([2, 3])\n"]},{"data":{"text/plain":["tensor([[ 27.,  30.,  33.],\n","        [ 61.,  68.,  75.],\n","        [ 95., 106., 117.]])"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["tensor_A = torch.tensor([[1, 2],\n","                         [3, 4],\n","                         [5, 6]], dtype=torch.float32)\n","\n","tensor_B = torch.tensor([[7, 10],\n","                         [8, 11], \n","                         [9, 12]], dtype=torch.float32)\n","\n","# Transpose\n","\n","print(tensor_B.T, tensor_B.T.shape)\n","\n","# torch.mm is a shortcut for matmul\n","torch.mm(tensor_A, tensor_B.T)\n"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original Matrix:\n","tensor([[1, 2, 3],\n","        [4, 5, 6],\n","        [7, 8, 9]])\n","\n","Transposed Matrix (torch.transpose):\n","tensor([[1, 4, 7],\n","        [2, 5, 8],\n","        [3, 6, 9]])\n","\n","Transposed Matrix (.t() method):\n","tensor([[1, 4, 7],\n","        [2, 5, 8],\n","        [3, 6, 9]])\n"]}],"source":["import torch\n","\n","# Original matrix\n","original_matrix = torch.tensor([[1, 2, 3],\n","                                [4, 5, 6],\n","                                [7, 8, 9]])\n","\n","# Transpose using torch.transpose\n","transposed_matrix = torch.transpose(original_matrix, 0, 1)\n","\n","# Transpose using .t() method\n","t_method_transposed_matrix = original_matrix.t()\n","\n","# Print the original and transposed matrices\n","print(\"Original Matrix:\")\n","print(original_matrix)\n","print(\"\\nTransposed Matrix (torch.transpose):\")\n","print(transposed_matrix)\n","print(\"\\nTransposed Matrix (.t() method):\")\n","print(t_method_transposed_matrix)"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.float32\n","torch.float16\n"]}],"source":["#change the datatypes of tensors\n","\n","# Create a tensor and check its datatype\n","tensor = torch.arange(10., 100., 10.)\n","print(tensor.dtype)\n","\n","# Create a float16 tensor\n","tensor_float16 = tensor.type(torch.float16)\n","print(tensor_float16.dtype)"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n","Minimum: 0\n","Maximum: 90\n","Mean: 45.0\n","Sum: 450\n","Index where max value occurs: 2\n","Index where min value occurs: 0\n"]}],"source":["# Create a tensor\n","x = torch.arange(0, 100, 10)\n","\n","print(x)\n","\n","print(f\"Minimum: {x.min()}\")\n","print(f\"Maximum: {x.max()}\")\n","print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n","print(f\"Sum: {x.sum()}\")\n","\n","# Returns index of max and min values\n","print(f\"Index where max value occurs: {tensor.argmax()}\")\n","print(f\"Index where min value occurs: {tensor.argmin()}\")"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-0.3609, -0.0606,  0.0733,  0.8187],\n","        [ 1.4805,  0.3449, -1.4241, -0.1163],\n","        [ 0.2176, -0.0467, -1.4335, -0.5665],\n","        [-0.4253,  0.2625, -1.4391,  0.5214]])\n"]},{"data":{"text/plain":["tensor([[-0.3609, -0.0606],\n","        [ 0.0733,  0.8187],\n","        [ 1.4805,  0.3449],\n","        [-1.4241, -0.1163],\n","        [ 0.2176, -0.0467],\n","        [-1.4335, -0.5665],\n","        [-0.4253,  0.2625],\n","        [-1.4391,  0.5214]])"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.randn(4, 4)\n","print(x)\n","\n","# Returns a new tensor with the same data as the self tensor but of a different shape\n","y = x.view(8,2)\n","y"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1., 2., 3., 4., 5., 6., 7.]) torch.Size([7])\n"]},{"data":{"text/plain":["(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.arange(1., 8.)\n","print(x, x.shape)\n","\n","# Add an extra dimension\n","x_reshaped = x.reshape(1, 7)\n","x_reshaped, x_reshaped.shape"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 2., 3., 4., 5., 6., 7.],\n","        [1., 2., 3., 4., 5., 6., 7.],\n","        [1., 2., 3., 4., 5., 6., 7.],\n","        [1., 2., 3., 4., 5., 6., 7.]])\n","tensor([[1., 1., 1., 1.],\n","        [2., 2., 2., 2.],\n","        [3., 3., 3., 3.],\n","        [4., 4., 4., 4.],\n","        [5., 5., 5., 5.],\n","        [6., 6., 6., 6.],\n","        [7., 7., 7., 7.]])\n"]}],"source":["# Stack tensors on top of each other\n","x_stacked = torch.stack([x, x, x, x], dim=0)\n","print(x_stacked)\n","\n","x_stacked = torch.stack([x, x, x, x], dim=1)\n","print(x_stacked)"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Previous tensor: tensor([[1., 2., 3., 4., 5., 6., 7.]])\n","Previous shape: torch.Size([1, 7])\n","\n","New tensor: tensor([1., 2., 3., 4., 5., 6., 7.])\n","New shape: torch.Size([7])\n"]}],"source":["print(f\"Previous tensor: {x_reshaped}\")\n","print(f\"Previous shape: {x_reshaped.shape}\")\n","\n","# Remove extra dimension from x_reshaped\n","x_squeezed = x_reshaped.squeeze()\n","print(f\"\\nNew tensor: {x_squeezed}\")\n","print(f\"New shape: {x_squeezed.shape}\")"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Previous tensor: tensor([1., 2., 3., 4., 5., 6., 7.])\n","Previous shape: torch.Size([7])\n","\n","New tensor: tensor([[1., 2., 3., 4., 5., 6., 7.]])\n","New shape: torch.Size([1, 7])\n"]}],"source":["print(f\"Previous tensor: {x_squeezed}\")\n","print(f\"Previous shape: {x_squeezed.shape}\")\n","\n","## Add an extra dimension with unsqueeze\n","x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n","print(f\"\\nNew tensor: {x_unsqueezed}\")\n","print(f\"New shape: {x_unsqueezed.shape}\")"]},{"cell_type":"markdown","metadata":{},"source":["The unsqueeze operation in PyTorch is used to add a dimension to a tensor at a specified location\n","\n","if you have a batch of images represented as a tensor of shape (batch_size, height, width, channels), you might use unsqueeze to add a batch dimension at the beginning, resulting in a tensor of shape (batch_size, 1, height, width, channels)."]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original Tensor: tensor([1, 2, 3]) torch.Size([3]) 1\n","Unsqueezed Tensor: tensor([[1],\n","        [2],\n","        [3]]) torch.Size([3, 1]) 2\n"]}],"source":["original_tensor = torch.tensor([1, 2, 3])\n","\n","# Unsqueeze operation to add a dimension at the specified location (index 1 in this case)\n","unsqueezed_tensor = original_tensor.unsqueeze(1)\n","\n","# Print the original and unsqueezed tensors\n","print(\"Original Tensor:\", original_tensor, original_tensor.shape, original_tensor.dim())\n","print(\"Unsqueezed Tensor:\", unsqueezed_tensor, unsqueezed_tensor.shape, unsqueezed_tensor.dim() )"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["(array([1., 2., 3., 4., 5., 6., 7.]),\n"," tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# NumPy array to tensor\n","import torch\n","import numpy as np  \n","array = np.arange(1.0, 8.0)\n","tensor = torch.from_numpy(array) #By default, NumPy arrays are created with the datatype float64 and if you convert it to a PyTorch tensor it'll keep the same datatype\n","array, tensor"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["(tensor([1., 1., 1., 1., 1., 1., 1.]),\n"," array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Tensor to NumPy array\n","tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n","numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n","tensor, numpy_tensor"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor C:\n","tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n","        [0.3904, 0.6009, 0.2566, 0.7936],\n","        [0.9408, 0.1332, 0.9346, 0.5936]])\n","\n","Tensor D:\n","tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n","        [0.3904, 0.6009, 0.2566, 0.7936],\n","        [0.9408, 0.1332, 0.9346, 0.5936]])\n","\n","Does Tensor C equal Tensor D? (anywhere)\n"]},{"data":{"text/plain":["tensor([[True, True, True, True],\n","        [True, True, True, True],\n","        [True, True, True, True]])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Reproducibility\n","\n","import torch\n","import random\n","\n","# # Set the random seed\n","RANDOM_SEED=42\n","torch.manual_seed(seed=RANDOM_SEED) \n","random_tensor_C = torch.rand(3, 4)\n","\n","# Have to reset the seed every time a new rand() is called \n","# Without this, tensor_D would be different to tensor_C \n","torch.random.manual_seed(seed=RANDOM_SEED) \n","random_tensor_D = torch.rand(3, 4)\n","\n","print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n","print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n","print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n","random_tensor_C == random_tensor_D"]}],"metadata":{"kernelspec":{"display_name":"dl_pytorch_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
